from self_attention.mhsa import MultiHeadSelfAttentionAISummer
# model = MultiHeadSelfAttentionAISummer(64)
# x = torch.rand(16, 10, 64)  # [batch, tokens, dim]
# y = model(x)
